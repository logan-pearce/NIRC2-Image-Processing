###############################################################################
#                                                                             #
#                        NIRC2 Image Processing pipeline                      #
#                                                                             #
#                        Written by Logan A. Pearce (2017)                    #
###############################################################################
#
# Pipeline for cleaning NIRC2 images for analysis.  The pipeline first creates a master dark
# frame by linearizing and median-combining dark frames, then a master flat by linearizing, dark-subtracting,
# and then median-combining flat frames.  It then dark-substracts and flat-divides the science images.
# Then the pipeline imports a list of known bad pixels for NIRC2 replaces them with the mean of
# surrounding pixels.
#
# Inputs:
#  All located in the same directory as this script:
#  - A list of science images called "objectlist" (generated by running the "finding_object.py" script)
#  - A list of dark frames called "darklist" (from "finding_darkflat.py")
#  - A list of flat frames called "flatlist" (from "finding_darkflat.py")
#  - A list of known bad pixels for NIRC2 for both 1024x1024 and 512x512 images
# 
# Outputs:
#  - Cleaned science images as .fits files in the same directory as the raw image
#
# From the terminal, execute as follows:
# python image_process.py
#

import numpy as np
from astropy import units as u
from astropy.io import fits
from astropy.io.fits import getheader
import os
import time
import warnings


# This code generates warnings about setting array values to nan and blanks in header
# keywords.  These aren't necessary to see and don't impact the function at all.
warnings.filterwarnings("ignore")

########################################## Make master dark ##########################################
print 'Making master dark......'
with open('darklist') as f:
    z = f.read().splitlines()

# Linearizing coefficients:
coeff = [1.001,-6.9e-6,-0.70e-10]

# Get the size of the dark frame for stacking:
drkhdr = getheader(z[0])
sizex=drkhdr['NAXIS1']
sizey=drkhdr['NAXIS2']
# Get the total number of dark frames to iterate over:
shape=len(z)
item=np.linspace(0,shape,shape+1,dtype=int)
# Initialize master dark image:
darkstack = np.zeros((shape,sizex,sizey))

#Importing darks, linearizing, and gain correcting each one for making master dark:
for line,i in zip(z,item):
    drkhdr = getheader(line)
    coadds = drkhdr['coadds']
    dark1i = fits.open(line)
    dark1s = dark1i[0].data
    norm1 = coeff[0]+(coeff[1]*(dark1s/coadds))+(coeff[2]*((dark1s/coadds)**2))
    dark1 = dark1s/norm1 #linearize the dark frames
    dark1 = dark1*4 #gain correction
    darkstack[i]= dark1

# Median combine the corrected dark frames into master dark frame:
masterdark = np.median(darkstack,axis=0)

dark_exposure = drkhdr['elaptime'] * u.second  #Calls the header to get exposure times
print 'done'

########################################## Make master flat ##########################################

#Counts the number of unique occurances of values and returns which value occurs the most.  
#Made this because the scipy mode function was so very slow on these files.
def mode(a):
    nums,counts = np.unique(a, return_counts=True)
    return nums[np.argmax(counts)]

print 'Making master flat.......'

#make master flat:
with open('flatlist') as f:
    y = f.read().splitlines()
shapef=len(y)
# If the number of flat frames exceeds 10, just cut it off at 10.  Sometimes there can be just
# too many flats for a single filter, more than 10 really isn't necessary.
if shapef > 10:
    shapef=10
else:
    pass

flthdr = getheader(y[0])
flat_exposure = flthdr['elaptime'] * u.second
coeff = [1.001,-6.9e-6,-0.70e-10]

#Importing flats, linearizing, gain correcting, and dark subtracting
#each one for making master flat:
item=np.linspace(0,shapef-1,shapef,dtype=int)
yf=[]
for i in item:
    yz=y[i]
    yf.append(yz)
yf = np.array(yf)

flatstack = np.zeros((yf.shape[0],sizex,sizey))
for line,i in zip(yf,item):
    flthdr = getheader(line)
    coadds = flthdr['coadds']
    flat1i = fits.open(line)
    flat1s = flat1i[0].data
    norm1 = coeff[0]+(coeff[1]*(flat1s/coadds))+(coeff[2]*((flat1s/coadds)**2))
    flat1l = flat1s/norm1 #linearize each flat frame
    flat1g = flat1l*4 #gain correct each flat frame
    flat1=flat1g-masterdark #Dark subtract each flat frame
    flat1 = flat1/mode(flat1) #Normalize each flat frame
    flatstack[i]= flat1

masterflat = np.median(flatstack,axis=0) #median combine flats
masterflat = masterflat / mode(masterflat)  #normalize master flat to mode value
print 'done'

#hdu = fits.PrimaryHDU(masterflat)
#hdu.writeto('masterflat.fits',overwrite=True)
#hdu = fits.PrimaryHDU(masterdark)
#hdu.writeto('masterdark.fits',overwrite=True)

############################### Dark subtract and flat divide each science frame: #################################

print 'Processing images..... '

#Input images to be processed:
with open('objectlist') as f:
    z = f.read().splitlines()

# Open header for first image to get the size:
imhdr = getheader(z[0])
shape = (imhdr['NAXIS1'],imhdr['NAXIS2'])

sampmode = imhdr['sampmode']
multisam = float(imhdr['multisam'])

data_exposure = imhdr['elaptime'] * u.second

for line in z:
    image1 = fits.open(line)
    image = image1[0].data
    imhdr = getheader(line)
    coadds = float(imhdr['coadds'])
    norm1 = coeff[0]+(coeff[1]*(flat1s/coadds))+(coeff[2]*((flat1s/coadds)**2))
    image = image/norm1 #linearize image
    ## Dark subtracted image
    ds_image = image - masterdark
    ## Flat divide image:
    flat_div = ds_image / masterflat
    newfilename = line.split('.')[0]+'.'+line.split('.')[1]+'.'+line.split('.')[2]+'.LDFC.'+line.split('.')[3]
    imhdr['COMMENT'] = '         Dark subtracted and flat corrected on '+time.strftime("%m/%d/%Y")+ ' By Logan A. Pearce'
    fits.writeto(newfilename,flat_div,imhdr,overwrite=True)
	
print 'done'

# Readnoise:
if sampmode == 3.0:
	readnoise = (38.0/np.sqrt(multisam)) * (np.sqrt(coadds))
elif sampmode == 2.0:
	readnoise = 38 * (np.sqrt(coadds))
else: 
	readnoise = 38 * (np.sqrt(coadds))


############################################# Bad pixel fix ###############################################
# Copied from:
# http://mtham.ucolick.org/egates/2016GradWorkshop/PDFs/DataReduction/DataReductionProcedures-Python-2016.pdf

# Depending on the size of the image, load the correct bad pixel list:
# (Python indicies are (row,column) so the image indicies are (y,x) in python; additionally python begins with
# initial index of 0, while image data begins at 1)
if imhdr['NAXIS1'] == 1024:
    badpix = np.loadtxt(open("nirc2.1024.1024.badpix","rb"))
    badpix = badpix.astype(int)
elif imhdr['NAXIS1'] == 512:
    badpix = np.loadtxt(open("nirc2.512.512.badpix","rb"))
    badpix = badpix.astype(int)
else:
    print "I don't have a bad pixel list to match this image size.  I only have 1024x1024 or 512x512.  \
    Check your image sizes please."
    quit()

print 'Fixing bad pixels...'
# Set how many pixels around each bad pixel to use for computing the mean by changing the integer value of s:
s=3
for line in z:
    # Open image:
    image1 = fits.open(line.split('.')[0]+'.'+line.split('.')[1]+'.'+line.split('.')[2]+'.LDFC.'+line.split('.')[3])
    image = image1[0].data
    imhdr = getheader(line.split('.')[0]+'.'+line.split('.')[1]+'.'+line.split('.')[2]+'.LDFC.'+line.split('.')[3])
    # Make a boolean mask the same size as the image and set all initial values to False:
    mask = np.ma.make_mask(image,copy=True,shrink=True, dtype=np.bool)
    mask[:,:] = False
    # For each bad pixel in the list, set the value of the mask to true:
    for i in badpix:
        mask[i[1]-1][i[0]-1] = True
    # Set the value of all bad pixels in the image to nan:
    mdata = np.ma.masked_array(image,mask=mask,fill_value=np.nan)
    # Make a new array as a copy of original image:
    badpixelfixed = image.copy()
    # For each x and y value, loop through image and replace the value of all "nan"
    # pixels with the mean of the four pixels on either side of the bad one:
    for i in range(0,mdata.shape[0]):
        for j in range(0,mdata.shape[1]):
            if np.math.isnan(mdata[i,j]):
                x1 = i-s
                x2 = i+s+1
                y1 = j-s
                y2 = j+s+1
                if x1<0:
                    x1 = 0
                if x2>mdata.shape[0]:
                    x2=mdata.shape[0]
                if y1<0:
                    y1 = 0
                if y2>mdata.shape[1]:
                    y2 = mdata.shape[1]
                badpixelfixed[i,j] = np.mean(mdata[x1:x2,y1:y2])
    # Write out the bad pixel corrected image to a new fits file:
    newfilename = line.split('.')[0]+'.'+line.split('.')[1]+'.'+line.split('.')[2]+'.LDFC.'+line.split('.')[3]
    fits.writeto(newfilename,badpixelfixed,imhdr,overwrite=True)

print 'Donezo.'
